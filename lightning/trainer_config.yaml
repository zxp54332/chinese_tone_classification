# pytorch_lightning==1.9.2
seed_everything: 42
trainer:
  logger: false
  enable_checkpointing: true
  callbacks: null
  default_root_dir: null
  gradient_clip_val: null
  gradient_clip_algorithm: null
  num_nodes: 1
  num_processes: null
  devices: [1]
  auto_select_gpus: null
  tpu_cores: null
  ipus: null
  enable_progress_bar: true
  overfit_batches: 0.0
  track_grad_norm: -1
  check_val_every_n_epoch: 1
  fast_dev_run: false
  accumulate_grad_batches: null
  max_epochs: 1
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  val_check_interval: null
  log_every_n_steps: 1
  accelerator: "gpu"
  strategy: null
  sync_batchnorm: false
  precision: 32
  enable_model_summary: true
  num_sanity_val_steps: 2
  resume_from_checkpoint: null
  profiler: null
  benchmark: null
  deterministic: true
  reload_dataloaders_every_n_epochs: 1
  auto_lr_find: false
  replace_sampler_ddp: true
  detect_anomaly: false
  auto_scale_batch_size: false
  plugins: null
  amp_backend: null
  amp_level: null
  move_metrics_to_cpu: false
  multiple_trainloader_mode: max_size_cycle
  inference_mode: true
model:
  model_name_or_path: "MIT/ast-finetuned-audioset-10-10-0.4593"
  num_labels: 5
  max_length: 75
  hidden_dropout_prob: 0.5
  ignore_mismatched_sizes: true
  lr: 2e-5
  weight_decay: 0.1
  mode: max
  factor: 0.5
  patience: 2
  threshold: 0.01
  interval: epoch
  frequency: 1
  monitor: val_acc
data:
  train_metadata: "/home/vincent0730/ML_chinese_tone_classification/test1000.csv"
  eval_metadata: "/home/vincent0730/ML_chinese_tone_classification/test1000.csv"
  model_name_or_path: "MIT/ast-finetuned-audioset-10-10-0.4593"
  audio_column_name: "path"
  max_length: 75
  batch_size: 128
  seed: 42

# optimizer:
#   class_path: torch.optim.AdamW
#   init_args:
#     lr: 3e-4
#     betas:
#     - 0.9
#     - 0.999
#     eps: 1.0e-08
#     weight_decay: 0.01
#     amsgrad: false
#     maximize: false
#     foreach: null
#     capturable: false
# lr_scheduler:
#   class_path: pytorch_lightning.cli.ReduceLROnPlateau
#   init_args:
#     monitor: "val_acc"
#     mode: "max"
#     factor: 0.5
#     patience: 2
#     threshold: 0.05
#     threshold_mode: rel
#     cooldown: 0
#     min_lr: 0.0
#     eps: 1.0e-08
#     verbose: true
